# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html
#
# We support interacting with a variety of data stores including local file systems, cloud, network and HDFS
#
# The Data Catalog supports being able to reference the same file using two different DataSet implementations
# (transcoding), templating and a way to reuse arguments that are frequently repeated. See more here:
# https://kedro.readthedocs.io/en/stable/data/data_catalog.html
#

# iris_local:
#   type: spark.SparkDataSet
#   filepath: data/01_raw/iris.csv
#   file_format: "csv"
#   load_args:
#     header: True
#     inferSchema: True
#   save_args:
#     sep: ','
#     header: True

## a√±ade al catalog un csv en un bucket de minio
data_raw_minio:
  type: pandas.CSVDataSet
  filepath: s3://prueba.concepto.eduardo/data/QUERES_DATCOM_2306071810.csv
  load_args:
    sep: '|'
  save_args:
    index: False
    encoding: "utf-8"
  credentials: dev_minio
  layer: raw

# iris:
#   type: spark.SparkDataSet
#   filepath: s3a://warehouse/default/IRIS_EDU_V3/metadata/*
#   file_format: arvo
#   credentials: dev_minio