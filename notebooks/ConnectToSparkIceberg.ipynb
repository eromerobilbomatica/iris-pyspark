{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e433e8c-b0ba-4a87-b97b-453e008d2f98",
   "metadata": {},
   "source": [
    "# Prueba de conexión de Jupyter a Spark-Iceberg (iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ffb03-02bb-4398-8ee5-8db9683296cb",
   "metadata": {},
   "source": [
    "## 1. Comprobaciones previas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a00232-b96c-4efd-9ed4-257beec097f4",
   "metadata": {},
   "source": [
    "- Versiones de los productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85be57f-4fc5-4577-b61e-eb4c7f06a335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016ac5ad-f9b6-44c9-a81a-8ee045feef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_362\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_362-8u372-ga~us1-0ubuntu1~22.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.362-b09, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3166873a-f541-4f84-bc23-d3e761d0846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/spark-3.3.1-bin-hadoop3/jars/spark-sql_2.12-3.3.1.jar\n"
     ]
    }
   ],
   "source": [
    "!find / -iname spark*.jar 2>/dev/null|grep sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4670f7-31f3-4f5b-943a-d7bf0f643b38",
   "metadata": {},
   "source": [
    "- Variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53875846-c53d-4017-8e50-1d096af11674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"AWS_REGION\"]\n",
    "#os.environ[\"AWS_ACCESS_KEY_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8b470-4075-4d54-a415-680fbaeb6589",
   "metadata": {},
   "source": [
    "## 2. Pre-requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db04cc8b-1040-46d1-b531-2f3652cb8a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==3.3.1\n",
      "  Using cached pyspark-3.3.1-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.5\n",
      "  Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522c10a-29fe-4d75-92ca-757dcb050bd7",
   "metadata": {},
   "source": [
    "## 3. Libs y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aee0ee3-fc49-4264-a273-ac194d6ac590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172.21.174.69'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, BooleanType\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark import SQLContext\n",
    "\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.1.0,org.mariadb.jdbc:mariadb-java-client:2.3.0,org.postgresql:postgresql:42.5.4 pyspark-shell'\n",
    "dst_lh_url  = os.environ.get('DST_LH_URL', 'spark://spark-master-0.spark-headless.demml.svc.cluster.local:7077')\n",
    "dst_lh_appn = os.environ.get('DST_LH_APPN', 'TestDesdeJupyter20230530g')\n",
    "import subprocess\n",
    "my_pod_ip = subprocess.run(['hostname', '-I'], stdout=subprocess.PIPE).stdout.decode('utf-8').strip(' \\n\\t')\n",
    "my_pod_ip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c50b8b-feaa-44e5-a854-9a0496caade2",
   "metadata": {},
   "source": [
    "## 4. Conexión al spark\n",
    "\n",
    "Primera prueba:\n",
    "- v 3.3_2.12\n",
    "- Incluyendo libs bases (por pbs con scala, amazon, ...)\n",
    "- Con io-impl a S3\n",
    "- Con env-vars de AWS (inyectadas via helm)\n",
    "- Con provider \"simple\" para autenticarse en S3 minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0bef3b5-0ab8-4791-a109-e241fc80c74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.21.174.69:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master-0.spark-headless.demml.svc.cluster.local:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TestDesdeJupyter20230530g</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4cbd7bed90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark2 = SparkSession.builder \\\n",
    "    .master(dst_lh_url) \\\n",
    "    .appName(dst_lh_appn) \\\n",
    "    .config('spark.jars.packages','org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.1.0,org.mariadb.jdbc:mariadb-java-client:2.3.0,org.postgresql:postgresql:42.5.4,software.amazon.awssdk:bundle:2.17.257,software.amazon.awssdk:url-connection-client:2.17.257,software.amazon.awssdk:s3:2.17.257,software.amazon.awssdk:iam:2.17.257,org.apache.hadoop:hadoop-aws:3.2.3') \\\n",
    "    .config('spark.sql.extensions','org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions') \\\n",
    "    .config('spark.sql.catalog.spark_catalog','org.apache.iceberg.spark.SparkSessionCatalog') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.catalog-impl','org.apache.iceberg.jdbc.JdbcCatalog') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.uri','jdbc:postgresql://postgresql:5432/iceberg') \\\n",
    "    .config('spark.driver.host', my_pod_ip) \\\n",
    "    .config('spark.sql.catalog.spark_catalog.jdbc.useSSL','false') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.jdbc.user','iceberg') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.jdbc.password','iceberg') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.warehouse','s3a://warehouse/') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.s3.endpoint','http://minio:9000') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO') \\\n",
    "    .config('spark.sql.defaultCatalog','spark_catalog') \\\n",
    "    .config('spark.hadoop.fs.s3a.endpoint','http://minio:9000') \\\n",
    "    .config('spark.hadoop.fs.s3a.access.key','admin') \\\n",
    "    .config('spark.hadoop.fs.s3a.secret.key','t4bl4red0nd4') \\\n",
    "    .config('spark.hadoop.fs.s3a.path.style.access','true') \\\n",
    "    .config('spark.hadoop.fs.s3a.impl','org.apache.hadoop.fs.s3a.S3AFileSystem') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .getOrCreate()\n",
    "spark2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b1124-db93-44a7-8838-c977dbb8ea19",
   "metadata": {},
   "source": [
    "## 5. Comprobaciones tras conexión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d910f3a-e7b6-4f2d-aeda-cbb089147c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|      catalog|namespace|\n",
      "+-------------+---------+\n",
      "|spark_catalog|  default|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark2.sql(\"show current namespace\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1678012-d52a-4bf8-aa24-f2a56d83fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark2.sql(\"show databases\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54745af9-bdea-4974-b415-bb6ad7a93dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark2.sql(\"show tables\").show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47596839-8d71-449b-9bbe-26ce6c4ec8f3",
   "metadata": {},
   "source": [
    "## 6. Creación de tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087f4bf-b4a8-4fe5-9501-fa639379075f",
   "metadata": {},
   "source": [
    "La siguiente instrucción... si ya has creado la tabla previamente... pues no hace falta (fallará)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a35f24b-6df7-4ddf-a2fd-8ab136cffd04",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table default.IRIS7 already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE TABLE default.IRIS7 (sepal_length double, sepal_width double, petal_length double, petal_width double, variety string) USING iceberg OPTIONS (\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwrite.object-storage.enabled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=true, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwrite.data.path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://warehouse/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m);\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/session.py:1034\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     sqlQuery \u001b[38;5;241m=\u001b[39m formatter\u001b[38;5;241m.\u001b[39mformat(sqlQuery, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table default.IRIS7 already exists"
     ]
    }
   ],
   "source": [
    "spark2.sql(\"CREATE TABLE default.IRIS7 (sepal_length double, sepal_width double, petal_length double, petal_width double, variety string) USING iceberg OPTIONS ('write.object-storage.enabled'=true, 'write.data.path'='s3://warehouse/');\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78560acf-f298-4fb2-98b9-f25c2256ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark2.sql(\"SELECT * FROM default.IRIS7\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802304f5-e522-4d94-82a5-5406485f6085",
   "metadata": {},
   "source": [
    "## 6. Cargo datos para meter dentro del iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53618ca8-c24e-4699-821a-7240bf4d1626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "iris = sklearn.datasets.load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9485a45-01ae-4976-8bfc-46b65702ef29",
   "metadata": {},
   "source": [
    "## 6. Carga de datos en iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd268fc-8e52-4f83-8ec9-c3c5f8aeb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "|         1.0|        1.0|         1.0|        1.0| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark2.sql(\"SELECT * FROM default.IRIS7\").show()\n",
    "spark2.sql(\"INSERT INTO default.IRIS7 VALUES (1.0, 1.0, 1.0, 1.0, 'Setosa') \")\n",
    "spark2.sql(\"SELECT * FROM default.IRIS7\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83231bfe-d0f3-4799-83ac-6dee5fd784a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema2 = StructType([\n",
    "  StructField(\"sepal_length\", DoubleType(), True),\n",
    "  StructField(\"sepal_width\", DoubleType(), True),\n",
    "  StructField(\"petal_length\", DoubleType(), True),\n",
    "  StructField(\"petal_width\", DoubleType(), True),\n",
    "  StructField(\"class\", StringType(), True)\n",
    "])\n",
    "\n",
    "data2 = ([(1.0, 1.0,1.0,1.0, \"Setosa\" )])\n",
    "\n",
    "df2 = spark2.createDataFrame(data2, schema=schema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a1404b-a8cd-4aeb-a56c-8780a8bfbc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(sepal_length=1.0, sepal_width=1.0, petal_length=1.0, petal_width=1.0, class='Setosa')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29cadd-1ee6-4970-869b-12d916b12bf7",
   "metadata": {},
   "source": [
    "## Carga directa desde S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6d06327-be67-4484-b1f5-7853a1975168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      class| date_test|\n",
      "+------------+-----------+------------+-----------+-----------+----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|2020-01-01|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|2020-01-02|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|2020-01-03|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|2020-01-04|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|2020-01-05|\n",
      "+------------+-----------+------------+-----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_df=spark2.read.parquet(\"s3a://iris/iris.parq\",header=True,inferSchema=True)\n",
    "s3_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65489f60-4009-46f4-a13f-6bd9a19f6e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
