{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6493405-23b2-45f9-849a-602a0dfecea5",
   "metadata": {},
   "source": [
    "# Comprobaciones de versiones instaladas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e899c11e-a2ea-4dca-986d-71991dbd57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf5ac75-52ae-45ef-b5df-097f7bf6cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_362\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_362-8u372-ga~us1-0ubuntu1~22.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.362-b09, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8c1554-0a22-4425-965e-544d10aace31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pyspark/jars/spark-sql_2.12-3.3.1.jar\n",
      "/usr/local/spark-3.3.1-bin-hadoop3/jars/spark-sql_2.12-3.3.1.jar\n"
     ]
    }
   ],
   "source": [
    "!find / -iname spark*.jar 2>/dev/null|grep sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5402206c-b10b-4005-a434-ecb064617e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"AWS_REGION\"]\n",
    "#os.environ[\"AWS_ACCESS_KEY_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19efa5f-5289-4e17-a573-207f90e77951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.3.1 in /opt/conda/lib/python3.8/site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /opt/conda/lib/python3.8/site-packages (from pyspark==3.3.1) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c1338-8e6e-443c-8ac4-bde69c1d8626",
   "metadata": {},
   "source": [
    "# Iniciar conexión spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aed4b31-d70a-4811-bc73-b9135cecdd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172.21.174.71'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, BooleanType\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark import SQLContext\n",
    "\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.1.0,org.mariadb.jdbc:mariadb-java-client:2.3.0,org.postgresql:postgresql:42.5.4 pyspark-shell'\n",
    "dst_lh_url  = os.environ.get('DST_LH_URL', 'spark://spark-master-0.spark-headless.demml.svc.cluster.local:7077')\n",
    "dst_lh_appn = os.environ.get('DST_LH_APPN', 'conexion_pyspark_iceberg_edu')\n",
    "import subprocess\n",
    "my_pod_ip = subprocess.run(['hostname', '-I'], stdout=subprocess.PIPE).stdout.decode('utf-8').strip(' \\n\\t')\n",
    "my_pod_ip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89b1820-63fe-44ad-94b1-147af40f7813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.21.174.71:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master-0.spark-headless.demml.svc.cluster.local:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>conexion_pyspark_iceberg_edu</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd801508940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(dst_lh_url) \\\n",
    "    .appName(dst_lh_appn) \\\n",
    "    .config('spark.jars.packages','org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.1.0,org.mariadb.jdbc:mariadb-java-client:2.3.0,org.postgresql:postgresql:42.5.4,software.amazon.awssdk:bundle:2.17.257,software.amazon.awssdk:url-connection-client:2.17.257,software.amazon.awssdk:s3:2.17.257,software.amazon.awssdk:iam:2.17.257,org.apache.hadoop:hadoop-aws:3.2.3') \\\n",
    "    .config('spark.sql.extensions','org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions') \\\n",
    "    .config('spark.sql.catalog.spark_catalog','org.apache.iceberg.spark.SparkSessionCatalog') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.catalog-impl','org.apache.iceberg.jdbc.JdbcCatalog') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.uri','jdbc:postgresql://postgresql:5432/iceberg') \\\n",
    "    .config('spark.driver.host', my_pod_ip) \\\n",
    "    .config('spark.sql.catalog.spark_catalog.jdbc.useSSL','false') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.jdbc.user','iceberg') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.jdbc.password','iceberg') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.warehouse','s3a://warehouse/') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.s3.endpoint','http://minio:9000') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO') \\\n",
    "    .config('spark.sql.defaultCatalog','spark_catalog') \\\n",
    "    .config('spark.hadoop.fs.s3a.endpoint','http://minio:9000') \\\n",
    "    .config('spark.hadoop.fs.s3a.access.key','admin') \\\n",
    "    .config('spark.hadoop.fs.s3a.secret.key','t4bl4red0nd4') \\\n",
    "    .config('spark.hadoop.fs.s3a.path.style.access','true') \\\n",
    "    .config('spark.hadoop.fs.s3a.impl','org.apache.hadoop.fs.s3a.S3AFileSystem') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e665cb26-b8b8-454f-a0b4-754de19cff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|      catalog|namespace|\n",
      "+-------------+---------+\n",
      "|spark_catalog|  default|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show current namespace\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eafd238-f20a-4086-9e00-6c6c03afbbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a1bf729-7a2b-4fce-b920-560bbdd82887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3787b56-5070-4ed7-aebc-b3c36c78492b",
   "metadata": {},
   "source": [
    "# Creación de tabla desde spark en minio (Iceberg)\n",
    "\n",
    "!!! NO borrar siguiente celda comentada ¡¡¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f129e7-4ce9-4f5f-9bab-80f4ad7a0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"CREATE TABLE default.IRIS_EDU_V3 (sepal_length double, sepal_width double, petal_length double, petal_width double, variety string, target int) USING iceberg OPTIONS ('write.object-storage.enabled'=true, 'write.data.path'='s3://warehouse/');\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b657be72-33b9-4df8-9ea9-da53b2c83045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|target|\n",
      "+------------+-----------+------------+-----------+-------+------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|     0|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|     0|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|     0|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|     0|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|     0|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|     0|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|     0|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|     0|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|     0|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|     0|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|     0|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|     0|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|     0|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|     0|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|     0|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|     0|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|     0|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|     0|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|     0|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|     0|\n",
      "+------------+-----------+------------+-----------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM spark_catalog.default.IRIS_EDU_V3\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648eb92-dc86-4610-b8af-f99b5df4ecd1",
   "metadata": {},
   "source": [
    "# Creo un dataframe de pyspark a partir de un dataframe de pandas y lo escribo en iceberg (se puede ver en minio) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da35da86-4b2f-413e-819d-52f36d8a2238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['variety'] = iris.target_names[iris.target]\n",
    "df['target'] = iris.target\n",
    "\n",
    "df.columns = ['sepal_length','sepal_width','petal_length','petal_width','variety','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0bfea67-6bf4-4f58-aade-5a3680eae817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/conda/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|target|\n",
      "+------------+-----------+------------+-----------+-------+------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|     0|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|     0|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|     0|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|     0|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|     0|\n",
      "+------------+-----------+------------+-----------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = spark.createDataFrame(df)\n",
    "dfs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a04b1a82-ce49-414b-8944-4da95912c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.write.format(\"iceberg\").mode(\"append\").save(\"default.IRIS_EDU_V3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "341db0ad-422f-4908-ba90-8c003233e457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|target|\n",
      "+------------+-----------+------------+-----------+-------+------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|     0|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|     0|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|     0|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|     0|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|     0|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|     0|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|     0|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|     0|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|     0|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|     0|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|     0|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|     0|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|     0|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|     0|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|     0|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|     0|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|     0|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|     0|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|     0|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|     0|\n",
      "+------------+-----------+------------+-----------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM spark_catalog.default.IRIS_EDU_V3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54959ec-c973-476b-96b7-69ca0292637d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
