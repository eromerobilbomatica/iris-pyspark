{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_362-362\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_362-362-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.362-b09, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5URi95VNn23"
   },
   "source": [
    "# **IRIS Naive Bayes Classification with Pyspark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gwe9FeysidtE",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.3.1 in /home/coder/miniconda3/envs/demml/lib/python3.8/site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/coder/miniconda3/envs/demml/lib/python3.8/site-packages (from pyspark==3.3.1) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "# install\n",
    "# !pip install Pyspark\n",
    "!pip install pyspark==3.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexi√≥n con el cluster de Spark con pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"AWS_REGION\"]\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.21.23.206:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master-0.spark-headless.demml.svc.cluster.local:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>iris_naive_bayes_classification_pyspark_EDU</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fec3bccf9a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.1.0,org.mariadb.jdbc:mariadb-java-client:2.3.0,org.postgresql:postgresql:42.5.4 pyspark-shell'\n",
    "dst_lh_url  = os.environ.get('DST_LH_URL', 'spark://spark-master-0.spark-headless.demml.svc.cluster.local:7077')\n",
    "dst_lh_appn = os.environ.get('DST_LH_APPN', 'iris_naive_bayes_classification_pyspark_EDU')\n",
    "import subprocess\n",
    "my_pod_ip = subprocess.run(['hostname', '-I'], stdout=subprocess.PIPE).stdout.decode('utf-8').strip(' \\n\\t')\n",
    "my_pod_ip\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(dst_lh_url) \\\n",
    "    .appName(dst_lh_appn) \\\n",
    "    .config('spark.jars.packages','org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.1.0,org.mariadb.jdbc:mariadb-java-client:2.3.0,org.postgresql:postgresql:42.5.4,software.amazon.awssdk:bundle:2.17.257,software.amazon.awssdk:url-connection-client:2.17.257,software.amazon.awssdk:s3:2.17.257,software.amazon.awssdk:iam:2.17.257,org.apache.hadoop:hadoop-aws:3.2.3') \\\n",
    "    .config('spark.sql.extensions','org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions') \\\n",
    "    .config('spark.sql.catalog.spark_catalog','org.apache.iceberg.spark.SparkSessionCatalog') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.catalog-impl','org.apache.iceberg.jdbc.JdbcCatalog') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.uri','jdbc:postgresql://postgresql:5432/iceberg') \\\n",
    "    .config('spark.driver.host', my_pod_ip) \\\n",
    "    .config('spark.sql.catalog.spark_catalog.jdbc.useSSL','false') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.jdbc.user','iceberg') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.jdbc.password','iceberg') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.warehouse','s3a://warehouse/') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.s3.endpoint','http://minio:9000') \\\n",
    "    .config('spark.sql.catalog.spark_catalog.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO') \\\n",
    "    .config('spark.sql.defaultCatalog','spark_catalog') \\\n",
    "    .config('spark.hadoop.fs.s3a.endpoint','http://minio:9000') \\\n",
    "    .config('spark.hadoop.fs.s3a.access.key','admin') \\\n",
    "    .config('spark.hadoop.fs.s3a.secret.key','t4bl4red0nd4') \\\n",
    "    .config('spark.hadoop.fs.s3a.path.style.access','true') \\\n",
    "    .config('spark.hadoop.fs.s3a.impl','org.apache.hadoop.fs.s3a.S3AFileSystem') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "import datetime as dt\n",
    "ini = dt.datetime.now()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xcsHrgdw6glu",
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_96743/4283484585.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;31m# read sklearn inbuilt data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/demml/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0mhas_pandas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_pandas\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# Create a DataFrame from pandas DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             return super(SparkSession, self).createDataFrame(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             )\n\u001b[1;32m    894\u001b[0m         return self._create_dataframe(\n",
      "\u001b[0;32m~/miniconda3/envs/demml/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    432\u001b[0m                         \u001b[0;34m\"has been set to false.\\n  %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                     )\n\u001b[1;32m    434\u001b[0m                     \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mconverted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/demml/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, pdf, schema, timezone)\u001b[0m\n\u001b[1;32m    470\u001b[0m                                 \u001b[0mcopied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                             \u001b[0mpdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mshould_localize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_timestamp_ntz_preferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mshould_localize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_series_convert_timestamps_tz_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/demml/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "# read sklearn inbuilt data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "iris = iris.frame\n",
    "iris = spark.createDataFrame(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRXO_exO6glv",
    "outputId": "7a90e4a4-f536-44e3-fbc1-020f331caf21",
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFDhxcnB6glv",
    "outputId": "d8a8bac0-6563-40c0-b048-b511b01159a8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TorzEMY6glw",
    "outputId": "0745875e-6c4b-4522-e015-db2e400d6fc6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZjuNOGL6glw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooSm4UaF6glw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "featureassembler= VectorAssembler(inputCols=['sepal length (cm)',\n",
    " 'sepal width (cm)',\n",
    " 'petal length (cm)',\n",
    " 'petal width (cm)'], outputCol='Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJt4WucO6glw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = featureassembler.transform(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jY_eaYl_6glw",
    "outputId": "9a7dadf0-792d-4341-f327-67521b41618d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08O1r4kX6glx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "modeldata = output.select('Features','target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyyYW9Ml6glx",
    "outputId": "134fb7db-9857-4660-fb99-4f03e939ff1f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "modeldata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KbpnDWC6glx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "train_data, test_data = modeldata.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZcfp4R26glx",
    "outputId": "f0292f68-2a9b-4202-df46-c86002ce9fd6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-RUxJVW6glx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# naive bayes model\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqAG3-Mc6glx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes(featuresCol='Features', labelCol='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5MoY_w46gly",
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb = nb.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyk6Ost36gly",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred = nb.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLNLJhI16gly",
    "outputId": "f7032172-3978-4e3a-8a5d-121e1e5aeab7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aP0v4QDgrP8Q",
    "outputId": "abe8c5b4-e70a-43c3-8f47-e388e3606c8a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "y_pred.groupBy('target', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57T0b7gOw_t9",
    "outputId": "6cd071ea-98b2-463e-d089-9cca765edd67",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = y_pred.select(\"prediction\").collect()\n",
    "orig = y_pred.select(\"target\").collect()\n",
    "print(confusion_matrix(orig, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1z9f4RbN_2NU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9keKjBLvxq_c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='target', predictionCol='prediction'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.metricName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNbJEY7A_3NG",
    "outputId": "5e49e02e-cfbc-4e50-f066-aa1659c60261",
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(y_pred)\n",
    "precision = evaluator.evaluate(y_pred, {evaluator.metricName: 'weightedPrecision'})\n",
    "recall = evaluator.evaluate(y_pred, {evaluator.metricName: 'weightedRecall'})\n",
    "f1_score = evaluator.evaluate(y_pred, {evaluator.metricName: 'f1'})\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5fn3z4r6gly",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# close connection to spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fin = dt.datetime.now()\n",
    "\n",
    "print(str(fin - ini))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
